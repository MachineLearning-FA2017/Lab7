{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment 7: Evaluation and Multi-Layer Perceptron\n",
    "## Rupal Sanghavi, Omar Roa, Van Tran\n",
    "# Business Case\n",
    "\n",
    "This dataset represents the responses from students and their friends(ages 15-30, henceforth stated as \"young people\") of a Statistics class from the Faculty of Social and Economic Sciences at The Comenius University in Bratislava, Slovakia. Their survey was a mix of various topics.\n",
    "\n",
    "* Music preferences (19 items)\n",
    "* Movie preferences (12 items)\n",
    "* Hobbies & interests (32 items)\n",
    "* Phobias (10 items)\n",
    "* Health habits (3 items)\n",
    "* Personality traits, views on life, & opinions (57 items)\n",
    "* Spending habits (7 items)\n",
    "* Demographics (10 items)\n",
    "\n",
    "The dataset can be found here. https://www.kaggle.com/miroslavsabo/young-people-survey\n",
    "\n",
    "Our target is to predict how likely a young person would spend money on gadgets. \n",
    "\n",
    "We wanted to find a classifer that would interest advertisers. Many of the questions asked here may not be something readily available or something that can be scraped from social media. These include phobias and spending habits that aren't the likeliness of spending money on gadgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline \n",
    "%load_ext memory_profiler\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.special import expit\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from memory_profiler import memory_usage\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "\n",
    "target_classifier = 'Spending on gadgets'\n",
    "df = pd.read_csv('responses.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "desired_features = [\"Music\",\"Dance\",\"Folk\",\"Country\",\"Classical music\",\"Musical\",\n",
    "    \"Pop\",\"Rock\",\"Metal or Hardrock\",\"Punk\",\"Hiphop, Rap\",\"Reggae, Ska\",\n",
    "    \"Swing, Jazz\",\"Rock n roll\",\"Alternative\",\"Latino\",\"Techno, Trance\",\n",
    "    \"Opera\",\"Movies\",\"Horror\",\"Thriller\",\"Comedy\",\"Romantic\",\"Sci-fi\",\"War\",\n",
    "    \"Fantasy/Fairy tales\",\"Animated\",\"Documentary\",\"Western\",\"Action\",\"History\",\n",
    "    \"Psychology\",\"Politics\",\"Mathematics\",\"Physics\",\"Internet\",\"PC\",\"Economy Management\",\n",
    "    \"Biology\",\"Chemistry\",\"Reading\",\"Geography\",\"Foreign languages\",\"Medicine\",\"Law\",\n",
    "    \"Cars\",\"Art exhibitions\",\"Religion\",\"Countryside, outdoors\",\"Dancing\",\n",
    "    \"Musical instruments\",\"Writing\",\"Passive sport\",\"Active sport\",\"Gardening\",\"Celebrities\",\n",
    "    \"Shopping\",\"Science and technology\",\"Theatre\",\"Fun with friends\",\"Adrenaline sports\",\n",
    "    \"Pets\",\"Smoking\",\"Alcohol\",\"Healthy eating\",\"Spending on gadgets\",\"Age\",\"Height\",\"Weight\",\n",
    "    \"Number of siblings\",\"Gender\",\"Left - right handed\",\"Education\",\"Village - town\",\"House - block of flats\"\n",
    "]\n",
    "\n",
    "df = df[desired_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our list of included features.  Most of these are the interest in a certain topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Smoking', 'Alcohol', 'Gender', 'Left - right handed', 'Education', 'Village - town', 'House - block of flats']\n"
     ]
    }
   ],
   "source": [
    "# remove rows whose target classfier value is NaN\n",
    "df_cleaned_classifier = df[np.isfinite(df[target_classifier])]\n",
    "# change NaN number values to the mean\n",
    "df_imputed = df_cleaned_classifier.fillna(np.floor(df_cleaned_classifier.mean()))\n",
    "# get categorical features\n",
    "object_features = list(df_cleaned_classifier.select_dtypes(include=['object']).columns)\n",
    "# drop anything that wasn't fixed\n",
    "df_imputed = df_imputed.dropna()\n",
    "print(object_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "encoders = dict() \n",
    "categorical_headers = object_features\n",
    "\n",
    "for col in categorical_headers:\n",
    "    df_imputed[col] = df_imputed[col].str.strip()    \n",
    "    if col==\"Spending on gadgets\":\n",
    "        tmp = LabelEncoder()\n",
    "        df_imputed[col] = tmp.fit_transform(df_imputed[col])\n",
    "    else:\n",
    "        encoders[col] = LabelEncoder()\n",
    "        df_imputed[col+'_int'] = encoders[col].fit_transform(df_imputed[col])\n",
    "\n",
    "numeric_headers = [feature for feature in desired_features if feature not in categorical_headers]\n",
    "\n",
    "for col in numeric_headers:\n",
    "    df_imputed[col] = df_imputed[col].astype(np.int)    \n",
    "#     ss = StandardScaler()\n",
    "#     df_imputed[col] = ss.fit_transform(df_imputed[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=3, random_state=None, test_size=0.2,\n",
      "            train_size=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if target_classifier in df_imputed:\n",
    "    y = df_imputed[target_classifier].values # get the labels we want\n",
    "    del df_imputed[target_classifier] # get rid of the class label\n",
    "    X = df_imputed.values # use everything else to predict!\n",
    "\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = StratifiedShuffleSplit(n_splits=num_cv_iterations,test_size = 0.2)\n",
    "\n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "\n",
    "            X_train = (X[train_indices])\n",
    "            y_train = y[train_indices]\n",
    "\n",
    "            X_test = (X[test_indices])\n",
    "            y_test = y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 2 3 1 4 2 2 5 1 4 3 1 1 1 2 3 1 2 1 5 3 1 4 1 3 2 1 2 3 3 2 2 2 2 2\n",
      " 4 4 3 1 2 1 4 1 2 4 2 1 3 2 5 2 4 1 5 2 5 5 2 3 5 5 2 5 1 3 1 3 3 4 4 1 2\n",
      " 5 2 5 3 4 4 3 3 1 3 5 2 1 3 3 3 2 1 3 3 2 3 1 3 1 1 5 3 3 3 1 1 4 2 2 4 2\n",
      " 2 2 1 3 1 4 2 5 5 4 2 1 1 4 2 4 5 5 2 2 1 3 4 1 1 2 4 2 4 5 4 5 1 5 2 1 1\n",
      " 2 5 1 3 2 3 2 2 3 3 4 2 1 2 2 2 4 5 3 4 5 3 4 4 2 3 4 2 5 1 2 3 2 3 4 3 1\n",
      " 2 2 3 2 2 1 4 3 3 1 5 3 5 2 1 4 2 2 3 4 2 2 2 4 3 3 2 2 1 3 4 3 4 2 3 2 3\n",
      " 2 3 4 2 5 1 1 2 2 4 5 2 3 3 2 3 3 2 1 1 1 4 2 4 2 5 3 3 3 2 5 4 1 4 4 2 2\n",
      " 4 5 4 4 4 4 3 3 3 3 4 4 3 1 1 2 3 3 3 1 5 2 3 3 3 3 5 1 3 5 3 3 2 5 4 4 1\n",
      " 5 4 5 3 2 5 4 3 4 2 2 3 4 3 5 4 3 3 3 2 2 1 2 5 1 2 4 2 3 4 5 3 3 2 1 4 4\n",
      " 2 4 1 5 2 5 3 5 4 3 5 3 1 5 1 3 5 2 5 5 4 3 5 4 3 3 1 4 5 2 2 1 5 1 3 2 3\n",
      " 2 3 3 3 4 3 3 4 5 5 2 4 1 1 2 3 4 5 3 5 5 3 2 2 2 5 3 4 2 2 3 2 1 4 1 3 2\n",
      " 5 1 1 3 2 3 2 1 3 1 3 4 2 1 2 4 5 2 5 4 1 5 2 3 4 2 4 2 4 1 5 1 5 4 2 1 4\n",
      " 4 2 4 3 3 3 2 5 5 5 4 2 2 2 2 4 3 3 2 1 3 2 1 1 4 2 5 3 2 2 3 2 5 1 2 3 3\n",
      " 3 2 3 2 1 2 3 3 2 3 3 3 5 2 5 1 2 1 3 4 3 4 2 2 1 2 2 4 2 2 3 3 4 3 3 1 1\n",
      " 4 2 1 2 3 3 4 2 1 3 3 1 5 4 3 2 2 1 1 5 2 3 3 2 3 3 4 2 2 4 2 2 3 1 4 5 4\n",
      " 5 3 2 1 1 3 2 2 1 5 2 2 2 3 3 4 5 5 1 3 1 1 2 1 2 3 2 2 3 5 2 2 4 4 2 3 3\n",
      " 4 1 4 4 2 5 3 2 2 5 2 5 3 4 2 3 3 5 1 1 5 2 2 4 5 4 5 3 2 4 1 2 3 1 3 3 2\n",
      " 4 2 5 2 4 2 4 2 3 5 4 1 4 1 3 4 3 1 4 2 1 5 4 3 5 4 2 4 5 4 3 3 3 5 4 4 3\n",
      " 2 4 3 2 3 5 5 1 3 3 5 5 3 4 4 5 3 1 5 3 2 1 2 4 1 3 4 4 4 4 5 5 3 5 3 1 4\n",
      " 5 1 5 1 2 1 4 3 5 3 2 4 3 3 2 1 5 1 2 1 2 2 1 4 2 2 4 1 1 3 5 3 5 2 3 3 3\n",
      " 2 4 4 5 1 2 2 3 3 5 3 4 3 2 3 2 4 4 2 4 2 4 2 4 5 3 3 3 1 3 3 5 1 3 2 5 2\n",
      " 2 3 3 1 5 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.learn.python import SKCompat\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "tf.logging.set_verbosity(tf.logging.WARN) # control the verbosity of tensor flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we need to tell tensorflow how many inputs to expect and what the data types will be\n",
    "# for this early example, everything is just numeric, real valued\n",
    "features_tf = [layers.real_valued_column('', dimension=X_train.shape[1])]\n",
    "clf = SKCompat(# wrap with SKCompat for easy usage like sklearn\n",
    "            learn.DNNClassifier(hidden_units=[50], feature_columns=features_tf)\n",
    "        )\n",
    "\n",
    "clf.fit(X_train,y_train,steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "\n",
    "yhat = clf.predict(X_test)\n",
    "# notice that the output needs some interpretation\n",
    "# as its not completely the same as sklearn\n",
    "yhat = yhat['classes']\n",
    "print(mt.confusion_matrix(y_test,yhat),\n",
    "      mt.accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
